{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Task\n",
    "## Perform PCA  on 50 Startups and get the best model using the following algorithms\n",
    "### 1. Linear Regression\n",
    "### 2. Linear SVR\n",
    "### 3. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>New York</td>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>California</td>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>Florida</td>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>California</td>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>Florida</td>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>California</td>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>Florida</td>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>California</td>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>Florida</td>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>California</td>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>New York</td>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>Florida</td>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>California</td>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>Florida</td>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>Florida</td>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>California</td>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>Florida</td>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>Florida</td>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>New York</td>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>Florida</td>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>California</td>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>Florida</td>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>California</td>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>New York</td>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>Florida</td>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>California</td>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>California</td>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>California</td>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>Florida</td>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>California</td>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>New York</td>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>California</td>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>New York</td>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>Florida</td>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>California</td>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>California</td>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0   165349.20       136897.80        471784.10    New York  192261.83\n",
       "1   162597.70       151377.59        443898.53  California  191792.06\n",
       "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3   144372.41       118671.85        383199.62    New York  182901.99\n",
       "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
       "5   131876.90        99814.71        362861.36    New York  156991.12\n",
       "6   134615.46       147198.87        127716.82  California  156122.51\n",
       "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
       "8   120542.52       148718.95        311613.29    New York  152211.77\n",
       "9   123334.88       108679.17        304981.62  California  149759.96\n",
       "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
       "11  100671.96        91790.61        249744.55  California  144259.40\n",
       "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
       "13   91992.39       135495.07        252664.93  California  134307.35\n",
       "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
       "15  114523.61       122616.84        261776.23    New York  129917.04\n",
       "16   78013.11       121597.55        264346.06  California  126992.93\n",
       "17   94657.16       145077.58        282574.31    New York  125370.37\n",
       "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
       "19   86419.70       153514.11             0.00    New York  122776.86\n",
       "20   76253.86       113867.30        298664.47  California  118474.03\n",
       "21   78389.47       153773.43        299737.29    New York  111313.02\n",
       "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
       "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
       "24   77044.01        99281.34        140574.81    New York  108552.04\n",
       "25   64664.71       139553.16        137962.62  California  107404.34\n",
       "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
       "27   72107.60       127864.55        353183.81    New York  105008.31\n",
       "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
       "29   65605.48       153032.06        107138.38    New York  101004.64\n",
       "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
       "31   61136.38       152701.92         88218.23    New York   97483.56\n",
       "32   63408.86       129219.61         46085.25  California   97427.84\n",
       "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
       "34   46426.07       157693.92        210797.67  California   96712.80\n",
       "35   46014.02        85047.44        205517.64    New York   96479.51\n",
       "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
       "37   44069.95        51283.14        197029.42  California   89949.14\n",
       "38   20229.59        65947.93        185265.10    New York   81229.06\n",
       "39   38558.51        82982.09        174999.30  California   81005.76\n",
       "40   28754.33       118546.05        172795.67  California   78239.91\n",
       "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
       "42   23640.93        96189.63        148001.11  California   71498.49\n",
       "43   15505.73       127382.30         35534.17    New York   69758.98\n",
       "44   22177.74       154806.14         28334.72  California   65200.33\n",
       "45    1000.23       124153.04          1903.93    New York   64926.08\n",
       "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
       "47       0.00       135426.92             0.00  California   42559.73\n",
       "48     542.05        51743.15             0.00    New York   35673.41\n",
       "49       0.00       116983.80         45173.06  California   14681.40"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading dataset\n",
    "df = pd.read_csv('50_Startups.csv')\n",
    "df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      "R&D Spend          50 non-null float64\n",
      "Administration     50 non-null float64\n",
      "Marketing Spend    50 non-null float64\n",
      "State              50 non-null object\n",
      "Profit             50 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()  # - Indicates that there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>73721.615600</td>\n",
       "      <td>121344.639600</td>\n",
       "      <td>211025.097800</td>\n",
       "      <td>112012.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>45902.256482</td>\n",
       "      <td>28017.802755</td>\n",
       "      <td>122290.310726</td>\n",
       "      <td>40306.180338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51283.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14681.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>39936.370000</td>\n",
       "      <td>103730.875000</td>\n",
       "      <td>129300.132500</td>\n",
       "      <td>90138.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>73051.080000</td>\n",
       "      <td>122699.795000</td>\n",
       "      <td>212716.240000</td>\n",
       "      <td>107978.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>101602.800000</td>\n",
       "      <td>144842.180000</td>\n",
       "      <td>299469.085000</td>\n",
       "      <td>139765.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>165349.200000</td>\n",
       "      <td>182645.560000</td>\n",
       "      <td>471784.100000</td>\n",
       "      <td>192261.830000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           R&D Spend  Administration  Marketing Spend         Profit\n",
       "count      50.000000       50.000000        50.000000      50.000000\n",
       "mean    73721.615600   121344.639600    211025.097800  112012.639200\n",
       "std     45902.256482    28017.802755    122290.310726   40306.180338\n",
       "min         0.000000    51283.140000         0.000000   14681.400000\n",
       "25%     39936.370000   103730.875000    129300.132500   90138.902500\n",
       "50%     73051.080000   122699.795000    212716.240000  107978.190000\n",
       "75%    101602.800000   144842.180000    299469.085000  139765.977500\n",
       "max    165349.200000   182645.560000    471784.100000  192261.830000"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() #Indicates that there are no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "box_df = df.iloc[:,[0,1,2]]\n",
    "box_df.plot(kind='box', figsize= (7,5),subplots=True, layout=(1,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R&D Spend          0\n",
       "Administration     0\n",
       "Marketing Spend    0\n",
       "State              0\n",
       "Profit             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check and Handle categorical data\n",
    "#State is the only categorical data that needs to be handled. Rest are numerica data\n",
    "df.State.unique()\n",
    "dfU = pd.concat([pd.get_dummies(df.State), df.iloc[:,[0,1,2,4]]] , axis = 1)\n",
    "#pd.get_dummies(df.Pincode)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dfU.iloc[:,:-1].values\n",
    "label = dfU.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us start with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rules/Guidelines:\n",
    "# 1. Always perform Standardization if you are planning to do PCA (MANDATORY)\n",
    "# 2. For PCA, n_components should be less than no of features\n",
    "# 3. n_components can be judged using PN's Technique\n",
    "#.   PN's Technique says that calc the principal component for n_components = n_features\n",
    "#.   Count the number of components greater than equal to 75%. The same count will be your\n",
    "#.   n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: Perform Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "features = sc.fit_transform(features)\n",
    "ideal_sc = sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step2: Identify the ideal number of components to work with\n",
    "#PNs Technique\n",
    "from sklearn.decomposition import PCA\n",
    "principalComponents = PCA(n_components=6)  #Here n_components = len(features)\n",
    "principalComponents.fit(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26596913e-01, 2.51852089e-01, 2.16730846e-01, 1.68048197e-01,\n",
       "       3.67719551e-02, 2.90831698e-33])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets get the ideal components (0.75 or later; else go with PC=1)\n",
    "principalComponents.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Based on above variance of each components, we conclude to go for n_components = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=1, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step3: Apply PCA with correct number of components\n",
    "from sklearn.decomposition import PCA\n",
    "principalComponentsFinal = PCA(n_components=1)  \n",
    "principalComponentsFinal.fit(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32659691])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalComponentsFinal.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step4: Transform the feature set\n",
    "finalFeatures = principalComponentsFinal.transform(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.6401699219533012 Train: 0.6379660973122546 RS: 1\n",
      "Test: 0.6495662283829913 Train: 0.6393846499133367 RS: 3\n",
      "Test: 0.7299723691319306 Train: 0.6176820798015509 RS: 6\n",
      "Test: 0.6480117576825599 Train: 0.5894680723002407 RS: 8\n",
      "Test: 0.6886747589957533 Train: 0.63359859270417 RS: 9\n",
      "Test: 0.6925605371955526 Train: 0.6343891997263071 RS: 10\n",
      "Test: 0.7563000224530768 Train: 0.6150585888690339 RS: 11\n",
      "Test: 0.6478521291413639 Train: 0.6389935337641339 RS: 14\n",
      "Test: 0.7819806699250693 Train: 0.6030945901184679 RS: 20\n",
      "Test: 0.8594313761307419 Train: 0.5883921893573438 RS: 21\n",
      "Test: 0.6416528158838661 Train: 0.6385542170077596 RS: 24\n",
      "Test: 0.6925955570853268 Train: 0.6226675635764436 RS: 29\n",
      "Test: 0.7688602666311564 Train: 0.5804159837102509 RS: 31\n",
      "Test: 0.793594856359698 Train: 0.5873008932345786 RS: 32\n",
      "Test: 0.8319991232828792 Train: 0.6031583130684616 RS: 33\n",
      "Test: 0.6594611401147334 Train: 0.6219134555201589 RS: 39\n",
      "Test: 0.7905100673005137 Train: 0.5533906255806452 RS: 40\n",
      "Test: 0.7294602813492721 Train: 0.6253595470650826 RS: 41\n",
      "Test: 0.7167709699956788 Train: 0.5760735185657735 RS: 45\n",
      "Test: 0.7185109788889761 Train: 0.6123808651028417 RS: 46\n",
      "Test: 0.6657660397673515 Train: 0.6021306784255949 RS: 48\n",
      "Test: 0.7541608390517467 Train: 0.6282245636870256 RS: 49\n",
      "Ideal model inside LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) \n",
      "Ideal LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "The random state for the max test score  of 0.8594313761307419 is 21  \n",
      "Since test score is greater than train score this model is good\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def determine_RS(features, label,model):\n",
    "    max_val = -10\n",
    "    max_train = -10\n",
    "    ideal_model = None\n",
    "    random_state = 0\n",
    "    xtrain=xtest=ytrain=ytest = 0\n",
    "    hit = 0 # This flag is fired when the test score is greater than train score\n",
    "    #Since there are 50 records lets try iteration over 200\n",
    "    for i in range(1,51):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                        label,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state = i)\n",
    "\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        train_score = model.score(X_train,y_train)\n",
    "        test_score = model.score(X_test,y_test)\n",
    "\n",
    "        if test_score > train_score:\n",
    "            hit = 1\n",
    "            #print (\"test %r \" % test_score)\n",
    "            #print (\"max val %r \" % max_val)\n",
    "            if test_score > max_val:\n",
    "                max_val = test_score\n",
    "                ideal_model = model\n",
    "                random_state = i\n",
    "                max_train = train_score\n",
    "                xtrain,xtest,ytrain,ytest = X_train,X_test,y_train,y_test\n",
    "            print(\"Test: {} Train: {} RS: {}\".format(test_score,train_score,i))\n",
    "    print (\"Ideal model inside %r \" % (ideal_model))\n",
    "    return [max_val,max_train, random_state, hit, ideal_model,xtrain,xtest,ytrain,ytest]\n",
    "model = LinearRegression()\n",
    "max_test_score_LR ,max_train_score_LR, random_state_LR, hit_LR ,ideal_model_LR,X_train_LR,X_test_LR,y_train_LR,y_test_LR= determine_RS(finalFeatures, label, model)\n",
    "\n",
    "print (\"Ideal %r\"  %ideal_model_LR)\n",
    "\n",
    "print (\"The random state for the max test score  of %r is %r  \" % (max_test_score_LR, random_state_LR))\n",
    "if hit_LR:\n",
    "    print (\"Since test score is greater than train score this model is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5809130094832935\n",
      "0.8768550668239933\n"
     ]
    }
   ],
   "source": [
    "print(ideal_model_LR.score(X_train_LR,y_train_LR))\n",
    "print(ideal_model_LR.score(X_test_LR,y_test_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Deployment without writing to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter R & D spend: \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-371-3c7e5e7a1f7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mR_and_D_spend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter R & D spend: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mAdmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter Admininstration: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mMarketing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter Marketing Spend: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mState\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter the state: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "R_and_D_spend = float(input(\"Enter R & D spend: \"))\n",
    "Admin = float(input(\"Enter Admininstration: \"))\n",
    "Marketing = float(input(\"Enter Marketing Spend: \"))\n",
    "State = input(\"Enter the state: \")\n",
    "\n",
    "#Features \n",
    "def  compute_feature(R_and_D_spend,Admin,Marketing, State):\n",
    "    if State == 'California':\n",
    "        featureSet = np.array([[1,0,0,R_and_D_spend,Admin,Marketing,]])\n",
    "        return featureSet\n",
    "    elif State == 'Florida':\n",
    "        featureSet = np.array([[0,1,0,R_and_D_spend,Admin,Marketing,]])\n",
    "        return featureSet\n",
    "    elif State == 'New York':\n",
    "        print (R_and_D_spend)\n",
    "        print (Admin)\n",
    "        print (Marketing)\n",
    "        featureSet = np.array([[0,0,1,R_and_D_spend,Admin,Marketing]])\n",
    "        #print (featureSet)\n",
    "\n",
    "        return featureSet\n",
    "    else:\n",
    "        State = input(\"Enter the right state:[ 'California', 'Florida', 'New York'] \")\n",
    "        return compute_feature(R_and_D_spend,Admin,Marketing, State)\n",
    "        \n",
    "featureSet=compute_feature(R_and_D_spend,Admin,Marketing, State)        \n",
    "#print (featureSet)\n",
    "\n",
    "def predict_now(model):\n",
    "    #Standardization\n",
    "\n",
    "    fSetStandardized = sc.transform(featureSet)\n",
    "\n",
    "    #Transform Feature to PCA component\n",
    "\n",
    "    finalF = principalComponentsFinal.transform(fSetStandardized)\n",
    "\n",
    "    #Predict\n",
    "\n",
    "    print(\"Your Profit will be %r \" % model.predict(finalF))\n",
    "predict_now(ideal_model_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy\n",
    "# 1. model Object\n",
    "# 2. StandardScaler Object\n",
    "# 3. PCA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_test_LR</th>\n",
       "      <th>PredictedProfit_LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-2.213714795095182]</td>\n",
       "      <td>159575.631532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[2.2053548373604532]</td>\n",
       "      <td>60447.412476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[1.5029600471214999]</td>\n",
       "      <td>76203.476630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[1.2125625751988283]</td>\n",
       "      <td>82717.649658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[-1.8119603752772406]</td>\n",
       "      <td>150563.508292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[-2.6938065376317053]</td>\n",
       "      <td>170345.011374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[-1.1278176331763883]</td>\n",
       "      <td>135216.872632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[0.5443926824723604]</td>\n",
       "      <td>97705.983630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>[-0.7802535001722678]</td>\n",
       "      <td>127420.341602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>[2.7192821471890958]</td>\n",
       "      <td>48919.035875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_test_LR  PredictedProfit_LR\n",
       "0   [-2.213714795095182]       159575.631532\n",
       "1   [2.2053548373604532]        60447.412476\n",
       "2   [1.5029600471214999]        76203.476630\n",
       "3   [1.2125625751988283]        82717.649658\n",
       "4  [-1.8119603752772406]       150563.508292\n",
       "5  [-2.6938065376317053]       170345.011374\n",
       "6  [-1.1278176331763883]       135216.872632\n",
       "7   [0.5443926824723604]        97705.983630\n",
       "8  [-0.7802535001722678]       127420.341602\n",
       "9   [2.7192821471890958]        48919.035875"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print root mean squared error (RMSE) from Linear Regression.\n",
    "#Creating a dataframe with test data and predicted output value\n",
    "import math\n",
    "PredictedProfit_LR = ideal_model_LR.predict(X_test_LR)\n",
    "predict_dataset_LR = pd.DataFrame({'X_test_LR': list(X_test_LR), 'PredictedProfit_LR': list(PredictedProfit_LR)}, columns=['X_test_LR', 'PredictedProfit_LR'])\n",
    "predict_dataset_LR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print root mean squared error (RMSE) from LR Model Tree based on all parameters is  14783.4733608116 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_LR = mean_squared_error(y_test_LR, PredictedProfit_LR)\n",
    "print (\"Print root mean squared error (RMSE) from LR Model Tree based on all parameters is  %r \" % math.sqrt(MSE_LR))\n",
    "RMSE_LR =  math.sqrt(MSE_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Deployment  writing to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deployment\n",
    "\n",
    "#Persisting the model\n",
    "#Package ---- pickle (Store and Load Memory Objects to/from disk respectively)\n",
    "\n",
    "import pickle\n",
    "pickle.dump(ideal_model_LR , open('ProfitPredictorLR','wb')) #Get the memory object and store it in a persistent file\n",
    "pickle.dump(ideal_sc , open('StandardScaler','wb')) \n",
    "pickle.dump(principalComponentsFinal , open('principalComponentsFinal','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: -4.569087835343495 Train: -9.42911399565845 RS: 1\n",
      "Test: -5.240942094719112 Train: -8.962868366318277 RS: 2\n",
      "Test: -5.7628274510102715 Train: -8.724992230429091 RS: 3\n",
      "Test: -5.452576037851747 Train: -8.844502987641558 RS: 6\n",
      "Test: -3.652772003851857 Train: -10.714608762439383 RS: 8\n",
      "Test: -6.557716140873875 Train: -8.279478691903256 RS: 10\n",
      "Test: -6.272284312218492 Train: -8.430819667603721 RS: 11\n",
      "Test: -7.261261545678606 Train: -8.257030562329296 RS: 12\n",
      "Test: -7.118927233760757 Train: -8.325397862527305 RS: 14\n",
      "Test: -6.184292995656259 Train: -9.661831454239607 RS: 18\n",
      "Test: -6.762452893498362 Train: -8.205226239406954 RS: 21\n",
      "Test: -7.200183325139657 Train: -8.27972119355018 RS: 26\n",
      "Test: -5.0213735683576495 Train: -9.103681160790924 RS: 29\n",
      "Test: -5.185519047031874 Train: -8.960164307981648 RS: 32\n",
      "Test: -5.870604238336955 Train: -8.773108308205924 RS: 37\n",
      "Test: -7.818812276120336 Train: -8.372066889447336 RS: 39\n",
      "Test: -4.6928677194953154 Train: -9.833607049112375 RS: 40\n",
      "Ideal model inside LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "          random_state=9, tol=0.001, verbose=0) \n",
      "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "          random_state=9, tol=0.001, verbose=0)\n",
      "The random state for the max test score  of -3.652772003851857 is 8  \n",
      "Linear SVR is not a good model\n",
      "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "          random_state=9, tol=0.001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "model = LinearSVR(random_state=9, tol=0.001)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "max_test_score_SVR ,max_train_score_SVR,random_state_SVR, hit_SVR ,ideal_model_SVR,X_train_SVR,X_test_SVR,y_train_SVR,y_test_SVR= determine_RS(finalFeatures, label, model)\n",
    "\n",
    "print (ideal_model_SVR)\n",
    "if max_test_score_SVR:\n",
    "    print (\"The random state for the max test score  of %r is %r  \" % (max_test_score_SVR, random_state_SVR))\n",
    "if hit:\n",
    "    print (\"Since test score is greater than train score this model is good\")\n",
    "else:\n",
    "    print (\"Linear SVR is not a good model\")\n",
    "print (ideal_model_SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment without writing to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter R & D spend: 89\n",
      "Enter Admininstration: 654\n",
      "Enter Marketing Spend: 654\n",
      "Enter the state: California\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "R_and_D_spend = float(input(\"Enter R & D spend: \"))\n",
    "Admin = float(input(\"Enter Admininstration: \"))\n",
    "Marketing = float(input(\"Enter Marketing Spend: \"))\n",
    "State = input(\"Enter the state: \")\n",
    "featureSet=compute_feature(R_and_D_spend,Admin,Marketing, State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Profit will be array([36.39425401]) \n"
     ]
    }
   ],
   "source": [
    "predict_now(ideal_model_SVR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment writing to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deployment\n",
    "\n",
    "#Persisting the model\n",
    "#Package ---- pickle (Store and Load Memory Objects to/from disk respectively)\n",
    "\n",
    "import pickle\n",
    "pickle.dump(ideal_model_SVR , open('ProfitPredictorSVR','wb')) #Get the memory object and store it in a persistent file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy\n",
    "# 1. model Object\n",
    "# 2. StandardScaler Object\n",
    "# 3. PCA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_test_SVR</th>\n",
       "      <th>PredictedProfit_SVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[2.2053548373604532]</td>\n",
       "      <td>37.647234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[2.592647645291922]</td>\n",
       "      <td>37.234053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-0.23969686592628459]</td>\n",
       "      <td>40.255719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-1.1278176331763883]</td>\n",
       "      <td>41.203204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[2.2374216126726587]</td>\n",
       "      <td>37.613023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[-1.2869706782609602]</td>\n",
       "      <td>41.372995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[-0.5273403615650528]</td>\n",
       "      <td>40.562589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[-2.5497373889745663]</td>\n",
       "      <td>42.720168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>[-0.7802535001722678]</td>\n",
       "      <td>40.832408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>[1.8652324516758994]</td>\n",
       "      <td>38.010091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X_test_SVR  PredictedProfit_SVR\n",
       "0    [2.2053548373604532]            37.647234\n",
       "1     [2.592647645291922]            37.234053\n",
       "2  [-0.23969686592628459]            40.255719\n",
       "3   [-1.1278176331763883]            41.203204\n",
       "4    [2.2374216126726587]            37.613023\n",
       "5   [-1.2869706782609602]            41.372995\n",
       "6   [-0.5273403615650528]            40.562589\n",
       "7   [-2.5497373889745663]            42.720168\n",
       "8   [-0.7802535001722678]            40.832408\n",
       "9    [1.8652324516758994]            38.010091"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print root mean squared error (RMSE) from Linear Regression.\n",
    "#Creating a dataframe with test data and predicted output value\n",
    "import math\n",
    "PredictedProfit_SVR = ideal_model_SVR.predict(X_test_SVR)\n",
    "predict_dataset_SVR = pd.DataFrame({'X_test_SVR': list(X_test_SVR), 'PredictedProfit_SVR': list(PredictedProfit_SVR)}, columns=['X_test_SVR', 'PredictedProfit_SVR'])\n",
    "predict_dataset_SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print root mean squared error (RMSE) from LR Model Tree based on all parameters is  62742.362360145285 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_SVR = mean_squared_error(y_test_SVR, PredictedProfit)\n",
    "print (\"Print root mean squared error (RMSE) from LR Model Tree based on all parameters is  %r \" % math.sqrt(MSE_SVR))\n",
    "RMSE_SVR = math.sqrt(MSE_SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal model inside None \n",
      "Random Forest is not a good model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "max_test_score_RF ,max_train_score_RF, random_state_RF, hit_RF ,ideal_model_RF,X_train_RF,X_test_RF,y_train_RF,y_test_RF= determine_RS(finalFeatures, label, model)\n",
    "\n",
    "if  random_state_RF!= 0:\n",
    "    print (\"The random state for the max test score  of %r is %r  \" % (max_test_score_RF, random_state_RF))\n",
    "if hit:\n",
    "    print (\"Since test score is greater than train score this model is good\")\n",
    "else:\n",
    "    print (\"Random Forest is not a good model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model':['RS','Test Score ' ,'Train Score' ,' Model is good', 'RMSE'],\n",
    "        'Linear Regression':[random_state_LR, max_test_score_LR,max_train_score_LR, 'Yes',RMSE_LR ],\n",
    "        'Linear SVR' :[random_state_SVR, max_test_score_SVR,max_train_score_SVR, 'Yes',RMSE_SVR],\n",
    "        'Random Forest':['NA',0.802,  0.9230,'No', 'NA']}\n",
    " \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: PCA for all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Linear SVR</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RS</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test Score</td>\n",
       "      <td>0.859431</td>\n",
       "      <td>-3.65277</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train Score</td>\n",
       "      <td>0.588392</td>\n",
       "      <td>-10.7146</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Model is good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>14783.5</td>\n",
       "      <td>62742.4</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Linear Regression Linear SVR Random Forest\n",
       "0              RS                21          8            NA\n",
       "1     Test Score           0.859431   -3.65277         0.802\n",
       "2     Train Score          0.588392   -10.7146         0.923\n",
       "3   Model is good               Yes        Yes            No\n",
       "4            RMSE           14783.5    62742.4            NA"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
